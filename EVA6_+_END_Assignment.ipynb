{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA6 + END Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJvfauUuY950o+0Wz+ESSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathbolla/EVA6/blob/Assignment-3/EVA6_%2B_END_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDZeFuQB9JNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f6ece5-206c-4fc1-fea3-a0491656e492"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May 23 14:44:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKQ29gi09PnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c98152d-c4bc-45d6-abcf-7e64370ff068"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from random import randint\n",
        "\n",
        "torch.set_printoptions(linewidth=120)\n",
        "\n",
        "# Setting up the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(\"The device available is: \", device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The device available is:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bS_sCyXx2Er"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LZd4ZHJ9bRn"
      },
      "source": [
        "## Combined Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mgYlWTUx2wg"
      },
      "source": [
        "def to_categorical(y,num_classes=10):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return (np.eye(num_classes, dtype='uint8')[y])\n",
        "def cat_array(x): ## This function is to add the second input (random numbers ) as one hot encoded vectors\n",
        "  return torch.from_numpy(np.array([to_categorical(xi) for xi in x]) )"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zLqHwb19on_"
      },
      "source": [
        "# Create a class to combine MNIST dataset and random numbers between 0 and 9\n",
        "class Combined_Dataset():\n",
        "\n",
        "  # We pass the train variable to get train or test data, and batch_size\n",
        "  def __init__(self, train, batch_size):\n",
        "\n",
        "      self.batch_size = batch_size\n",
        "      # Load the MNIST data into the data_loader object\n",
        "      self.data_loader = torch.utils.data.DataLoader(\n",
        "          torchvision.datasets.MNIST('/files/', train=train, download=True,\n",
        "                                transform=torchvision.transforms.Compose([\n",
        "                                  torchvision.transforms.ToTensor(),\n",
        "                                  torchvision.transforms.Normalize(\n",
        "                                    (0.1307,), (0.3081,))\n",
        "                                ])),\n",
        "          batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "      # Number of samples in the dataaset\n",
        "      self.dataset = self.data_loader.dataset            \n",
        "\n",
        "  # getitem function creats batches of our dataset on the fly by calling next(iter())\n",
        "  def __getitem__(self, index):\n",
        "      # Extract one batch of the MNIST data_loader\n",
        "      image, label = next(iter(self.data_loader))\n",
        "\n",
        "      # Generate randoms numbers between 0 and 9 of size=batch_size. The datatype is float as this is the input required for the network\n",
        "      random_numbers = torch.tensor([randint(0,9) for _ in range(self.batch_size)], dtype=torch.int8)\n",
        "      #print(random_numbers.shape)\n",
        "      np_random_numbers = random_numbers.numpy()\n",
        "      #print(\"NUmpy Random Numbers\", np_random_numbers.shape, type(np_random_numbers))\n",
        "      # Combine inputs and outputs as a list after transfering the tensors to the GPU\n",
        "      cat_rand_array = cat_array(np_random_numbers)\n",
        "      #print(\"Cat Random Numbers Input shape\", cat_rand_array.shape)\n",
        "      x = [image.to(device), cat_rand_array.to(device)]\n",
        "      #print(\"Random Numbers Input shape\", x[1].shape)\n",
        "      #x = [image.to(device), random_numbers.to(device)]\n",
        "      # y labels for addition of number is reshaped to [32,1] as MSE requires it in this format\n",
        "      #y = [label.to(device), (label+random_numbers).reshape([32,1]).to(device)]\n",
        "      y = [label.to(device), (label+random_numbers).to(device)]\n",
        "      #print(y[0],y[1])\n",
        "\n",
        "\n",
        "      return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data_loader)\n",
        "\n",
        "# Set the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the train and test dataset\n",
        "train_data = Combined_Dataset(train=True, batch_size=batch_size)\n",
        "test_data = Combined_Dataset(train=False, batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UAMCBPn9suv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a1286e-10e5-4bfc-8377-e2a1904d5d57"
      },
      "source": [
        "print(f\"Number of train batches: {len(train_data)}\")\n",
        "print(f\"Number of test batches: {len(test_data)}\")\n",
        "\n",
        "print(f\"Number of train samples: {len(train_data.dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_data.dataset)}\")\n",
        "\n",
        "x, y = next(iter(train_data))\n",
        "\n",
        "print(f\"Shape of input data is: [{x[0].shape}, {x[1].shape}]\")\n",
        "print(f\"Shape of output data is: [{y[0].shape}, {y[1].shape}]\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train batches: 1875\n",
            "Number of test batches: 313\n",
            "Number of train samples: 60000\n",
            "Number of test samples: 10000\n",
            "Shape of input data is: [torch.Size([32, 1, 28, 28]), torch.Size([32, 10])]\n",
            "Shape of output data is: [torch.Size([32]), torch.Size([32])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC-K_jFB9vSA"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkQDm47y9xEu"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,32, 3,padding=0,bias=False ) #28\n",
        "    self.conv2 = nn.Conv2d(32,16, 3,padding=0,bias=False ) #26\n",
        "    self.conv3 = nn.Conv2d(16, 12,3, padding=0, bias=False)\n",
        "    self.conv4 = nn.Conv2d(12,10,5, padding=0, bias=False)\n",
        "    self.linear1 = nn.Linear(10, 100)\n",
        "    self.linear2 = nn.Linear(100,10)\n",
        "    self.linear3 = nn.Linear(20,100)\n",
        "    self.linear4 = nn.Linear(100,19)\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "  def forward(self, X, Y):\n",
        "    X = F.relu(self.conv1(X)) #26\n",
        "    X = F.relu(self.conv2(X)) #24\n",
        "    X = F.max_pool2d(X, 2)   #12\n",
        "    X = F.relu(self.conv3(X)) #10\n",
        "    X = F.max_pool2d(X, 2) #5x5 16\n",
        "    X = F.relu(self.conv4(X))   #1x1 10\n",
        "    X = self.flatten(X) # 10\n",
        "    X1 = X\n",
        "    X = F.relu(self.linear1(X))\n",
        "    X = self.linear2(X)\n",
        "    Y = Y.type(torch.cuda.FloatTensor)\n",
        "    Y = torch.cat((X1,Y),1) # This will result in 20 dimensions\n",
        "    Y = F.relu(self.linear3(Y))\n",
        "    Y = self.linear4(Y)\n",
        "    return X, Y"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrb9cc1R92XP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0528a831-d0a9-49b5-8b7d-53bf2a0c6c91"
      },
      "source": [
        "!pip install torchsummary"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGyWFfc894s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23af4c7-038d-44d0-db43-dc1143cf30c9"
      },
      "source": [
        "# Setting up the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(\"The device available is: \", device)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The device available is:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHl4HNfo972A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5606e428-975c-4148-e284-730a7b195570"
      },
      "source": [
        "# Create an object of the class Network and transfer it to the GPU\n",
        "model = Model().to(device)\n",
        "print(\" The model layers are: \")\n",
        "print(model)\n",
        "\n",
        "print(\"\\nShape of parameters in each layer is: \")\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, '\\t\\t', param.shape)\n",
        "\n",
        "# Selecting the loss function and optimizer  for the model\n",
        "CE_loss = nn.CrossEntropyLoss()\n",
        "MSE_loss = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The model layers are: \n",
            "Model(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (conv3): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (conv4): Conv2d(12, 10, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "  (linear1): Linear(in_features=10, out_features=100, bias=True)\n",
            "  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (linear3): Linear(in_features=20, out_features=100, bias=True)\n",
            "  (linear4): Linear(in_features=100, out_features=19, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n",
            "\n",
            "Shape of parameters in each layer is: \n",
            "conv1.weight \t\t torch.Size([32, 1, 3, 3])\n",
            "conv2.weight \t\t torch.Size([16, 32, 3, 3])\n",
            "conv3.weight \t\t torch.Size([12, 16, 3, 3])\n",
            "conv4.weight \t\t torch.Size([10, 12, 5, 5])\n",
            "linear1.weight \t\t torch.Size([100, 10])\n",
            "linear1.bias \t\t torch.Size([100])\n",
            "linear2.weight \t\t torch.Size([10, 100])\n",
            "linear2.bias \t\t torch.Size([10])\n",
            "linear3.weight \t\t torch.Size([100, 20])\n",
            "linear3.bias \t\t torch.Size([100])\n",
            "linear4.weight \t\t torch.Size([19, 100])\n",
            "linear4.bias \t\t torch.Size([19])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcLszxG1DD9Y"
      },
      "source": [
        ""
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsZdyDNaDEX4"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5vjQLaC-AMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ada6ac8-312c-4dc7-fc6b-45eeea6b96b2"
      },
      "source": [
        "for epoch in range(10):  # Loop over the dataset multiple times\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_correct_1, total_correct_2 = 0, 0\n",
        "    # Loop over the entire length of train data\n",
        "    for i in range(len(train_data)):\n",
        "        # Get the inputs and outputs\n",
        "        # Input data x is a list of [images, random numbers], output data y is a list of [classes, sum of numbers]\n",
        "        x, y = next(iter(train_data))\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        output1, output2 = model(x[0], x[1])\n",
        "        loss = CE_loss(output1, y[0]) + CE_loss(output2, y[1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate statistics\n",
        "        total_loss += loss.item()\n",
        "        total_correct_1 += output1.argmax(dim=1).eq(y[0]).sum().item()\n",
        "        total_correct_2 += output2.argmax(dim=1).eq(y[1]).sum().item()\n",
        "        \n",
        "    # Print statistics        \n",
        "    print(f\"Epoch: {epoch+1}, loss: {total_loss}, Classification Acc: {100 * (total_correct_1/(len(train_data.dataset)))}, Addition Acc: {100 * (total_correct_2/(len(train_data.dataset)))}\")\n",
        "   \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 3274.9952426701784, Classification Acc: 90.94333333333333, Addition Acc: 56.49166666666666\n",
            "Epoch: 2, loss: 493.1207237690687, Classification Acc: 97.605, Addition Acc: 96.64833333333334\n",
            "Epoch: 3, loss: 332.56705613806844, Classification Acc: 98.015, Addition Acc: 97.41833333333332\n",
            "Epoch: 4, loss: 262.2368424870074, Classification Acc: 98.34, Addition Acc: 97.89\n",
            "Epoch: 5, loss: 237.37269268836826, Classification Acc: 98.50999999999999, Addition Acc: 98.095\n",
            "Epoch: 6, loss: 207.51043169386685, Classification Acc: 98.65833333333333, Addition Acc: 98.29333333333334\n",
            "Epoch: 7, loss: 193.6566683165729, Classification Acc: 98.71166666666666, Addition Acc: 98.35833333333333\n",
            "Epoch: 8, loss: 201.59544334141538, Classification Acc: 98.66, Addition Acc: 98.32666666666667\n",
            "Epoch: 9, loss: 191.7558812100906, Classification Acc: 98.71, Addition Acc: 98.37333333333333\n",
            "Epoch: 10, loss: 167.6414496623911, Classification Acc: 98.885, Addition Acc: 98.62166666666667\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPX4OBWPDIK4"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ExaNK2yAwF",
        "outputId": "03699680-5e5c-49da-d632-f99f7614bb5c"
      },
      "source": [
        "test_correct_1, test_correct_2 = 0, 0\n",
        "total_1, total_2 = 0, 0\n",
        "\n",
        "# Since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    # Loop over the entire length of test data\n",
        "    for i in range(len(test_data)):\n",
        "        # Get the inputs and outputs\n",
        "        # Input data x is a list of [images, random numbers], output data y is a list of [classes, sum of numbers]\n",
        "        x, y = next(iter(test_data))\n",
        "\n",
        "        # Calculate outputs by running data through the network \n",
        "        output1, output2 = model(x[0], x[1])\n",
        "        \n",
        "        total_1 += y[0].size(0)\n",
        "        test_correct_1 += output1.argmax(dim=1).eq(y[0]).sum().item()\n",
        "\n",
        "        total_2 += y[1].to(device).size(0)\n",
        "        test_correct_2 += output2.argmax(dim=1).eq(y[1]).sum().item()\n",
        "        \n",
        "\n",
        "print('Accuracy of the network on the 10,000 test images: ', (100 * test_correct_1 / total_1))\n",
        "print('Accuracy of the network on the 10,000 test random number input: ', (100 * test_correct_2 / total_2))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10,000 test images:  98.47244408945687\n",
            "Accuracy of the network on the 10,000 test random number input:  98.18290734824281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em0TtFsJFT_C"
      },
      "source": [
        "## Batch Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewlZiLT6FV_d",
        "outputId": "4dc1b726-89d5-431f-a30a-ebd1c0ffa5a3"
      },
      "source": [
        "\n",
        "print(\"Print Prediction for a sample batch\\n\")\n",
        "x, y = next(iter(test_data))\n",
        "\n",
        "# Calculate outputs by running data through the network \n",
        "output1, output2 = model(x[0], x[1])\n",
        "\n",
        "# The class with the highest energy is what we choose as prediction\n",
        "_, predicted = torch.max(output1.data, 1)\n",
        "\n",
        "print(\"Predicted vs. Actual for classifer\\n\")\n",
        "print(torch.stack((predicted, y[0]), dim=1)[:10])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print Prediction for a sample batch\n",
            "\n",
            "Predicted vs. Actual for classifer\n",
            "\n",
            "tensor([[1, 1],\n",
            "        [5, 5],\n",
            "        [2, 2],\n",
            "        [2, 2],\n",
            "        [3, 3],\n",
            "        [6, 6],\n",
            "        [0, 0],\n",
            "        [9, 9],\n",
            "        [9, 9],\n",
            "        [3, 3]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYUGi2HNIj8g",
        "outputId": "cab57ad6-917b-4d14-ea97-1c1ea9e02696"
      },
      "source": [
        "x[1].argmax(dim=1)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8, 8, 7, 1, 0, 2, 7, 5, 1, 0, 3, 5, 8, 2, 1, 7, 6, 2, 4, 3, 8, 6, 7, 0, 2, 3, 9, 9, 2, 1, 5, 7],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwBxBmdMIm1p",
        "outputId": "ea17a6fe-d528-4e3d-ad03-1f4896efcd38"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 5, 2, 2, 3, 6, 0, 9, 9, 3, 2, 2, 1, 7, 7, 2, 1, 9, 5, 0, 6, 1, 3, 1, 8, 4, 1, 3, 0, 5, 7, 9],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KhjwACKJoEo",
        "outputId": "792314a0-4860-4e18-e156-3f7ecdeed529"
      },
      "source": [
        "y[1]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9, 13,  9,  3,  3,  8,  7, 14, 10,  3,  5,  7,  9,  9,  8,  9,  7, 11,  9,  3, 14,  7, 10,  1, 10,  7, 10, 12,\n",
              "         2,  6, 12, 16], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRAi6EJIHsiS",
        "outputId": "69900f6f-6981-424b-99ba-1d5ec524e56d"
      },
      "source": [
        "## Random Number prediction\n",
        "output2.argmax(dim=1)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9, 13,  9,  3,  3,  8,  7, 14, 10,  3,  5,  7,  9,  9,  8,  9,  7, 11,  9,  3, 14,  7, 10,  1, 10,  7, 10, 12,\n",
              "         2,  6, 12, 16], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWrPz9keFqaf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}