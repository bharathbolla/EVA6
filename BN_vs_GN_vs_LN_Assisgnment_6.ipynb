{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BN vs GN vs LN_Assisgnment-6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathbolla/EVA6/blob/S-6/BN_vs_GN_vs_LN_Assisgnment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kH16rnZ7wt_"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yBQXitROay7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHdAGIdhxgnn",
        "outputId": "6052a689-de15-4e4d-9944-cd7f0ed4f841"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-M9BwiWyv6N"
      },
      "source": [
        "# this performs the import from the model.py file\n",
        "import model\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM7UTxlb9wOz"
      },
      "source": [
        "from model import Model, BatchNet, GroupNet, LayerNet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNKsFOtgCj4j"
      },
      "source": [
        "\n",
        "nn_model = Model(BatchNet(), GroupNet(), LayerNet())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4zdk4cBFLed",
        "outputId": "61c6ab05-ccef-4d9e-86e3-230963488536"
      },
      "source": [
        "params = list(nn_model.GN.parameters())\n",
        "for p in params:\n",
        "  print(p.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([8, 12, 1, 1])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([16, 12, 3, 3])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "torch.Size([12, 16, 1, 1])\n",
            "torch.Size([15, 12, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([15, 15, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([10, 15, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6CNSXBuFvhl",
        "outputId": "17002f27-48c5-4f32-b181-2454ef19c979"
      },
      "source": [
        "params = list(nn_model.BN.parameters())\n",
        "for p in params:\n",
        "  print(p.size())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([8, 12, 1, 1])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([16, 12, 3, 3])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "torch.Size([12, 16, 1, 1])\n",
            "torch.Size([15, 12, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([15, 15, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([10, 15, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kisW6JB8F85V",
        "outputId": "05c8db7f-e1cd-4c35-e28a-8fcedd469b12"
      },
      "source": [
        "params = list(nn_model.BN.parameters())\n",
        "for p in params:\n",
        "  print(p.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([8, 12, 1, 1])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([16, 12, 3, 3])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "torch.Size([12, 16, 1, 1])\n",
            "torch.Size([15, 12, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([15, 15, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([10, 15, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoEKAfd80O5x"
      },
      "source": [
        "/content/model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed_-NVMACv-S",
        "outputId": "74a05ab1-44bd-4f6d-8861-5abddfe43c6d"
      },
      "source": [
        "\n",
        "\n",
        "for param in nn_model.parameters():\n",
        "    print( param.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([8, 12, 1, 1])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([16, 12, 3, 3])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "torch.Size([12, 16, 1, 1])\n",
            "torch.Size([15, 12, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([15, 15, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([10, 15, 1, 1])\n",
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([8, 12, 1, 1])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([16, 12, 3, 3])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "torch.Size([12, 16, 1, 1])\n",
            "torch.Size([15, 12, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([15, 15, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([10, 15, 1, 1])\n",
            "torch.Size([8, 1, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([8, 12, 1, 1])\n",
            "torch.Size([12, 8, 3, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([12])\n",
            "torch.Size([16, 12, 3, 3])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "torch.Size([12, 16, 1, 1])\n",
            "torch.Size([15, 12, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([15, 15, 3, 3])\n",
            "torch.Size([15])\n",
            "torch.Size([15])\n",
            "torch.Size([10, 15, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNdGZiNDJxpY"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                                   transforms.RandomRotation((-12.0, 12.0), fill=(1,)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                   ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                   ])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A84rlfDA23"
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8OLDR79DrHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a605b221-447d-48d0-947d-675290a5091f"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQL3H6RJL3h"
      },
      "source": [
        "# The model\n",
        "Let's start with the model we first saw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1NIcqbqVxjh"
      },
      "source": [
        "##### Train and Test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSQdSBSrvx_p"
      },
      "source": [
        "# creating the train and\n",
        "from tqdm import tqdm\n",
        "\n",
        "train_losses_BN = []\n",
        "train_losses_GN = []\n",
        "train_losses_LN = []\n",
        "\n",
        "test_losses_BN = []\n",
        "test_losses_GN = []\n",
        "test_losses_LN = []\n",
        "\n",
        "train_acc_BN = []\n",
        "train_acc_GN = []\n",
        "train_acc_LN = []\n",
        "\n",
        "test_acc_BN = []\n",
        "test_acc_GN = []\n",
        "test_acc_LN = []\n",
        "\n",
        "\n",
        "train_losses_epoch_BN = []\n",
        "train_losses_epoch_GN = []\n",
        "train_losses_epoch_LN = []\n",
        "\n",
        "test_losses_epoch_BN = []\n",
        "test_losses_epoch_GN = []\n",
        "test_losses_epoch_LN = []\n",
        "\n",
        "train_acc_epoch_BN = []\n",
        "train_acc_epoch_GN = []\n",
        "train_acc_epoch_LN = []\n",
        "\n",
        "test_acc_epoch_BN = []\n",
        "test_acc_epoch_GN = []\n",
        "test_acc_epoch_LN = []\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer_BN, optimizer, GN, optimizer_LN, epoch, lamnda_l1 = 0.01, l1= False):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  incorrect = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    \n",
        "    y_pred_BN, y_pred_GN, y_pred_LN = model(data)\n",
        "    \n",
        "    ##BN\n",
        "\n",
        "    optimizer_BN.zero_grad()  \n",
        "    loss_BN = F.nll_loss(y_pred_BN, target)\n",
        "    loss_BN.backward()\n",
        "    optimizer_BN.step()\n",
        "    train_losses_BN.append(loss)\n",
        "    \n",
        "    # GN\n",
        "    optimizer_GN.zero_grad()\n",
        "    loss_GN = F.nll_loss(y_pred_GN, target)\n",
        "    loss_GN.backward()\n",
        "    optimizer_GN.step()\n",
        "    train_losses_GN.append(loss)\n",
        "\n",
        "    #3 LN   \n",
        "    # Calculate loss----------------------------------------------------------------------------------\n",
        "    optimizer_LN.zero_grad()\n",
        "    loss_LN = F.nll_loss(y_pred_LN, target)\n",
        "    loss_LN.backward()\n",
        "    optimizer_LN.step() \n",
        "    train_losses_LN.append(loss)   \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    # l1 = 0\n",
        "    # if l1 == True:\n",
        "    #     for p in Model.GN.parameters:\n",
        "    #         l1 = l1 + p.abs().sum()\n",
        "    # # adding the l1 loss\n",
        "    #     loss_ = loss + lambda_l1 *l1   \n",
        "    # --------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    # Backpropagation\n",
        "\n",
        "\n",
        "    # Update pbar-tqdm    \n",
        "    pred_BN = y_pred_BN.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    pred_GN = y_pred_GN.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    pred_LN = y_pred_LN.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "\n",
        "    correct_BN += pred_BN.eq(target.view_as(pred_BN)).sum().item()\n",
        "    correct_GN += pred_GN.eq(target.view_as(pred_GN)).sum().item()\n",
        "    correct_LN += pred_LN.eq(target.view_as(pred_LN)).sum().item()\n",
        "    \n",
        "    processed+= len(data)\n",
        "\n",
        "\n",
        "    # finding out incorrect values\n",
        "    # batch_incorrect = processed - correct\n",
        "    # incorrect  = incorrect + batch_incorrect\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss_BN.item()} Batch_id={batch_idx} Accuracy={100*correct_BN/processed:0.2f}')\n",
        "    pbar.set_description(desc= f'Loss={loss_GN.item()} Batch_id={batch_idx} Accuracy={100*correct_GN/processed:0.2f}')\n",
        "    pbar.set_description(desc= f'Loss={loss_LN.item()} Batch_id={batch_idx} Accuracy={100*correct_LN/processed:0.2f}')\n",
        "\n",
        "    train_acc_BN.append(100*correct_BN/processed)\n",
        "    train_acc_GN.append(100*correct_GN/processed)\n",
        "    train_acc_LN.append(100*correct_LN/processed)\n",
        "\n",
        "\n",
        "    # # finding out incorrect values\n",
        "    # batch_incorrect = processed - correct\n",
        "    # incorrect  = incorrect + batch_incorrect\n",
        "\n",
        "  train_losses_epoch_BN.append(sum(train_losses_BN)/len(train_losses_BN)) \n",
        "  train_acc_epoch_BN.append(sum(train_acc_BN)/len(train_acc_BN))\n",
        "  train_losses_epoch_GN.append(sum(train_losses_GN)/len(train_losses_GN)) \n",
        "  train_acc_epoch_GN.append(sum(train_acc_GN)/len(train_acc_GN))\n",
        "  train_losses_epoch_LN.append(sum(train_losses_LN)/len(train_losses_LN)) \n",
        "  train_acc_epoch_LN.append(sum(train_acc_LN)/len(train_acc_LN)) \n",
        "\n",
        "\n",
        "# def test(model, device, test_loader):\n",
        "#     model.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     with torch.no_grad():\n",
        "#         for data, target in test_loader:\n",
        "#             data, target = data.to(device), target.to(device)\n",
        "#             output = model(data)\n",
        "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "#             # processed += len(data)\n",
        "#             # test_acc.append(100*correct/processed)\n",
        "\n",
        "#     test_loss /= len(test_loader.dataset)\n",
        "#     test_losses.append(test_loss)\n",
        "\n",
        "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "#         test_loss, correct, len(test_loader.dataset),\n",
        "#         100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "#     test_acc.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAtoBzWrO324",
        "outputId": "c8098ded-be60-4f20-e077-8c8857d62b5b"
      },
      "source": [
        "# !pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqeiP1PpNaIP"
      },
      "source": [
        "batchnet = BatchNet()\n",
        "groupnet = GroupNet()\n",
        "layernet = LayerNet()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35DZaeZDK0X9"
      },
      "source": [
        "nn_model = Model(batchnet, groupnet, layernet)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C57eXMyjWT1V"
      },
      "source": [
        "#### Batch Net implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "iP2CYjoTWNv3",
        "outputId": "4d949518-3d82-4ecb-c73d-8ae2514ff6c3"
      },
      "source": [
        "model = nn_model().to(device)\n",
        "#summary(nn_model, input_size=(1, 28, 28))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-78d921763487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#summary(nn_model, input_size=(1, 28, 28))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtBzmTknWN0j",
        "outputId": "163b0727-6743-431a-a2af-cedf40451b09"
      },
      "source": [
        "optimizer = optim.SGD(batch_model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "EPOCHS = 3\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(batch_model, device, train_loader, optimizer, epoch, l1 = True)\n",
        "    scheduler.step()\n",
        "    test(batch_model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Loss=0.06407332420349121 Batch_id=468 Accuracy=88.86: 100%|██████████| 469/469 [00:20<00:00, 23.16it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0791, Accuracy: 9786/10000 (97.86%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04572343826293945 Batch_id=468 Accuracy=97.53: 100%|██████████| 469/469 [00:20<00:00, 22.49it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0505, Accuracy: 9846/10000 (98.46%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03412448987364769 Batch_id=468 Accuracy=98.09: 100%|██████████| 469/469 [00:21<00:00, 21.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0452, Accuracy: 9870/10000 (98.70%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "TR44BW1dR461",
        "outputId": "bace45e4-b4a5-4ac0-c8fc-f8e50b6b5e95"
      },
      "source": [
        "super_train_trac.append(train_acc_epoch)\n",
        "super_train_trlo.append(train_losses_epoch)\n",
        "super_train_teac.append(test_acc)\n",
        "super_train_telo.append(test_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7618c1145aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfirst_model_trac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfirst_model_trlo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfirst_model_teac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfirst_model_telo\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             raise RuntimeError(\"Only Tensors created explicitly by the user \"\n\u001b[0m\u001b[1;32m     56\u001b[0m                                \"(graph leaves) support the deepcopy protocol at the moment\")\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpTrUOBefEkq"
      },
      "source": [
        "##### Layer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCMXeFFNg5gU"
      },
      "source": [
        "# !pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "\n",
        "layer_model = LayerNet().to(device)\n",
        "summary(layer_model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX-Zlgmqy19a"
      },
      "source": [
        "optimizer = optim.SGD(layer_model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "EPOCHS = 3\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(layer_model, device, train_loader, optimizer, epoch)\n",
        "    scheduler.step()\n",
        "    test(layer_model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nhVJ4bntn7y"
      },
      "source": [
        "second_model_trac = copy.deepcopy(train_acc_epoch)\n",
        "second_model_trlo = copy.deepcopy(train_losses_epoch)\n",
        "second_model_teac = copy.deepcopy(test_acc)\n",
        "second_model_telo  = copy.deepcopy(test_losses)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHx5RJwMuByt"
      },
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.plot(first_model_trac)\n",
        "plt.plot(second_model_trac)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(first_model_telo)\n",
        "plt.plot(second_model_telo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mod6czI3fdgX"
      },
      "source": [
        "##### Group normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2HC8O_hmvy0",
        "outputId": "6a182abe-a5f9-4e20-f204-3360db5a5430"
      },
      "source": [
        "group_model = GroupNet().to(device)\n",
        "summary(group_model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              72\n",
            "              ReLU-2            [-1, 8, 26, 26]               0\n",
            "         GroupNorm-3            [-1, 8, 26, 26]              16\n",
            "            Conv2d-4           [-1, 12, 24, 24]             864\n",
            "              ReLU-5           [-1, 12, 24, 24]               0\n",
            "         GroupNorm-6           [-1, 12, 24, 24]              24\n",
            "            Conv2d-7            [-1, 8, 24, 24]              96\n",
            "         MaxPool2d-8            [-1, 8, 12, 12]               0\n",
            "            Conv2d-9           [-1, 12, 10, 10]             864\n",
            "             ReLU-10           [-1, 12, 10, 10]               0\n",
            "        GroupNorm-11           [-1, 12, 10, 10]              24\n",
            "           Conv2d-12             [-1, 16, 8, 8]           1,728\n",
            "             ReLU-13             [-1, 16, 8, 8]               0\n",
            "        GroupNorm-14             [-1, 16, 8, 8]              32\n",
            "           Conv2d-15             [-1, 12, 8, 8]             192\n",
            "        MaxPool2d-16             [-1, 12, 4, 4]               0\n",
            "           Conv2d-17             [-1, 15, 4, 4]           1,620\n",
            "             ReLU-18             [-1, 15, 4, 4]               0\n",
            "        GroupNorm-19             [-1, 15, 4, 4]              30\n",
            "           Conv2d-20             [-1, 15, 4, 4]           2,025\n",
            "             ReLU-21             [-1, 15, 4, 4]               0\n",
            "        GroupNorm-22             [-1, 15, 4, 4]              30\n",
            "        AvgPool2d-23             [-1, 15, 1, 1]               0\n",
            "           Conv2d-24             [-1, 10, 1, 1]             150\n",
            "================================================================\n",
            "Total params: 7,767\n",
            "Trainable params: 7,767\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.40\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.43\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UtbF-1gWSFv",
        "outputId": "c333cbb7-9bb3-408f-b5ec-bab08d71c816"
      },
      "source": [
        "optimizer = optim.SGD(group_model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "EPOCHS = 15\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(group_model, device, train_loader, optimizer, epoch)\n",
        "    scheduler.step()\n",
        "    test(group_model, device, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              72\n",
            "              ReLU-2            [-1, 8, 26, 26]               0\n",
            "         GroupNorm-3            [-1, 8, 26, 26]              16\n",
            "            Conv2d-4           [-1, 12, 24, 24]             864\n",
            "              ReLU-5           [-1, 12, 24, 24]               0\n",
            "         GroupNorm-6           [-1, 12, 24, 24]              24\n",
            "            Conv2d-7            [-1, 8, 24, 24]              96\n",
            "         MaxPool2d-8            [-1, 8, 12, 12]               0\n",
            "            Conv2d-9           [-1, 12, 10, 10]             864\n",
            "             ReLU-10           [-1, 12, 10, 10]               0\n",
            "        GroupNorm-11           [-1, 12, 10, 10]              24\n",
            "           Conv2d-12             [-1, 16, 8, 8]           1,728\n",
            "             ReLU-13             [-1, 16, 8, 8]               0\n",
            "        GroupNorm-14             [-1, 16, 8, 8]              32\n",
            "           Conv2d-15             [-1, 12, 8, 8]             192\n",
            "        MaxPool2d-16             [-1, 12, 4, 4]               0\n",
            "           Conv2d-17             [-1, 15, 4, 4]           1,620\n",
            "             ReLU-18             [-1, 15, 4, 4]               0\n",
            "        GroupNorm-19             [-1, 15, 4, 4]              30\n",
            "           Conv2d-20             [-1, 15, 4, 4]           2,025\n",
            "             ReLU-21             [-1, 15, 4, 4]               0\n",
            "        GroupNorm-22             [-1, 15, 4, 4]              30\n",
            "        AvgPool2d-23             [-1, 15, 1, 1]               0\n",
            "           Conv2d-24             [-1, 10, 1, 1]             150\n",
            "================================================================\n",
            "Total params: 7,767\n",
            "Trainable params: 7,767\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.40\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.43\n",
            "----------------------------------------------------------------\n",
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Loss=0.12374579161405563 Batch_id=468 Accuracy=86.31: 100%|██████████| 469/469 [00:13<00:00, 34.00it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0893, Accuracy: 9750/10000 (97.50%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.026314927265048027 Batch_id=468 Accuracy=97.06: 100%|██████████| 469/469 [00:13<00:00, 33.90it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0583, Accuracy: 9831/10000 (98.31%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07523234933614731 Batch_id=468 Accuracy=97.76: 100%|██████████| 469/469 [00:13<00:00, 33.67it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0467, Accuracy: 9867/10000 (98.67%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06346209347248077 Batch_id=468 Accuracy=98.14: 100%|██████████| 469/469 [00:13<00:00, 33.57it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0468, Accuracy: 9869/10000 (98.69%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03561898693442345 Batch_id=468 Accuracy=98.45: 100%|██████████| 469/469 [00:14<00:00, 33.41it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0325, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03192941099405289 Batch_id=468 Accuracy=98.91: 100%|██████████| 469/469 [00:13<00:00, 34.03it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0278, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07331002503633499 Batch_id=468 Accuracy=98.97: 100%|██████████| 469/469 [00:13<00:00, 33.90it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0274, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.006077084690332413 Batch_id=468 Accuracy=99.00: 100%|██████████| 469/469 [00:14<00:00, 33.28it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0269, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.009832638315856457 Batch_id=468 Accuracy=98.99: 100%|██████████| 469/469 [00:13<00:00, 34.63it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0258, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.05119304358959198 Batch_id=468 Accuracy=99.06: 100%|██████████| 469/469 [00:13<00:00, 34.83it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0270, Accuracy: 9920/10000 (99.20%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.015730200335383415 Batch_id=468 Accuracy=99.07: 100%|██████████| 469/469 [00:13<00:00, 35.10it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0258, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03598126396536827 Batch_id=468 Accuracy=99.12: 100%|██████████| 469/469 [00:13<00:00, 34.77it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0257, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.042304277420043945 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:13<00:00, 35.24it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0254, Accuracy: 9927/10000 (99.27%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.05491850897669792 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:13<00:00, 33.90it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0255, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03589383140206337 Batch_id=468 Accuracy=99.09: 100%|██████████| 469/469 [00:14<00:00, 32.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0254, Accuracy: 9928/10000 (99.28%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdTynUZlZ9f9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}